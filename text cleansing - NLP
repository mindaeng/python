# check the text -> there are too many things to remove(punctuation, emoji, etc)
for i in range(50):
    print(test['text'][i])
    

# start text cleansing

import numpy as np
import pandas as pd 
import matplotlib.pyplot as plt
import seaborn as sns
plt.style.use('seaborn-white')

import warnings
warnings.filterwarnings('ignore')

import tensorflow as tf 

from tensorflow.keras.layers import Dense, Embedding, Bidirectional, LSTM, Dropout
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences

train = pd.read_csv("/content/drive/MyDrive/Class/AI_DeepLearning 2022-1/project/data/train.csv")
test = pd.read_csv("/content/drive/MyDrive/Class/AI_DeepLearning 2022-1/project/data/test.csv")
submission = pd.read_csv("/content/drive/MyDrive/Class/AI_DeepLearning 2022-1/project/data/sample_submission.csv")


# text cleaning - remove URL, HTML, punctuation, 특수문자 등
import re
import string

def remove_URL(text):
    url = re.compile(r'https?://\S+')
    return url.sub(r' httpsmark ', text)


def remove_html(text):
    html = re.compile(r'<.*?>')
    return html.sub(r'', text)


def remove_atsymbol(text):
    name = re.compile(r'@\S+')
    return name.sub(r' atsymbol ', text)


def remove_hashtag(text):
    hashtag = re.compile(r'#')
    return hashtag.sub(r' hashtag ', text)


def remove_exclamation(text):
    exclamation = re.compile(r'!')
    return exclamation.sub(r' exclamation ', text)


def remove_question(text):
    question = re.compile(r'?')
    return question.sub(r' question ', text)


def remove_punc(text):
    return text.translate(str.maketrans('','',string.punctuation))


def remove_number(text):
    number = re.compile(r'\d+')
    return number.sub(r' number ', text)


def remove_emoji(string):
    emoji_pattern = re.compile("["
                               u"\U0001F600-\U0001F64F"  # emoticons
                               u"\U0001F300-\U0001F5FF"  # symbols & pictographs
                               u"\U0001F680-\U0001F6FF"  # transport & map symbols
                               u"\U0001F1E0-\U0001F1FF"  # flags (iOS)
                               u"\U00002500-\U00002BEF"  # chinese char
                               u"\U00002702-\U000027B0"
                               u"\U00002702-\U000027B0"
                               u"\U000024C2-\U0001F251"
                               u"\U0001f926-\U0001f937"
                               u"\U00010000-\U0010ffff"
                               u"\u2640-\u2642"
                               u"\u2600-\u2B55"
                               u"\u200d"
                               u"\u23cf"
                               u"\u23e9"
                               u"\u231a"
                               u"\ufe0f"  # dingbats
                               u"\u3030"
                               "]+", flags=re.UNICODE)
    return emoji_pattern.sub(r' emoji ', string)


train['text'] = train['text'].str.lower()
train['text'] = train['text'].apply(lambda text: remove_URL(text))
train['text'] = train['text'].apply(lambda text: remove_html(text))
train['text'] = train['text'].apply(lambda text: remove_atsymbol(text))
train['text'] = train['text'].apply(lambda text: remove_hashtag(text))
train['text'] = train['text'].apply(lambda text: remove_exclamation(text))
train['text'] = train['text'].apply(lambda text: remove_punc(text))
train['text'] = train['text'].apply(lambda text: remove_number(text))
train['text'] = train['text'].apply(lambda text: remove_emoji(text))




test['text']  = test['text'].str.lower()
test['text']  = test['text'].apply(lambda text: remove_URL(text))
test['text']  = test['text'].apply(lambda text: remove_html(text))
test['text']  = test['text'].apply(lambda text: remove_atsymbol(text))
test['text']  = test['text'].apply(lambda text: remove_hashtag(text))
test['text']  = test['text'].apply(lambda text: remove_exclamation(text))
test['text']  = test['text'].apply(lambda text: remove_punc(text))
test['text']  = test['text'].apply(lambda text: remove_number(text))
test['text']  = test['text'].apply(lambda text: remove_emoji(text))


def remove_S_and_N(text):
  return re.sub("[^A-Za-z ']"," ",text)
train['text']  = train['text'].apply(lambda text: remove_S_and_N(text))

def remove_S_and_N(text):
  return re.sub("[^A-Za-z ']"," ",text)
test['text']  = test['text'].apply(lambda text: remove_S_and_N(text))


# checking whether they are removed well or not
for i in range(50):
  print(test['text'][i])
  
  
def remove_Spaces(text):
  return re.sub('%20', ' ', str(text))
test['keyword'] = test['keyword'].apply(lambda text: remove_Spaces(text))
train['keyword'] = train['keyword'].apply(lambda text: remove_Spaces(text))

train[train.iloc[:,:] == 'nan'] = np.NaN
print(train.isnull().sum())
test[test.iloc[:,:] == 'nan'] = np.NaN
print(test.isnull().sum())

train["keyword"].value_counts()





